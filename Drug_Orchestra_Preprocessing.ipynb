{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec336211",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing Imports\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1ab51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drug, _, label\n",
    "\n",
    "def concatenate_label_data(df1, df2, labeldf):\n",
    "    df1_T = df1.T\n",
    "    df2_T = df2.T\n",
    "    \n",
    "    X = []\n",
    "    y = np.array(labeldf.iloc[:, -1:].values)\n",
    "    \n",
    "    for index, row in labeldf.iterrows():\n",
    "        drug_name = row[0]\n",
    "        vector_name = row[1]\n",
    "\n",
    "        # Fetch the corresponding embeddings\n",
    "        drug_embedding = df1_T.loc[drug_name].values\n",
    "        vector_embedding = df2_T.loc[vector_name].values\n",
    "\n",
    "        # Concatenate the embeddings\n",
    "        concatenated_embedding = np.concatenate((drug_embedding, vector_embedding))\n",
    "\n",
    "        # Add the concatenated embedding to the feature list\n",
    "        X.append(concatenated_embedding)\n",
    "\n",
    "    # Convert the list of feature vectors into a numpy array for further processing\n",
    "    X = np.array(X)\n",
    "\n",
    "    # Check the shapes of X and y to ensure they are as expected\n",
    "    print(X.shape, y.shape)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f93173",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace with path to data_InSummary\n",
    "path = '../PM 1/data_InSummary/Drug_{}/{}/drug_embedding.csv'\n",
    "\n",
    "response_2_path = '../PM 1/data_InSummary/Drug_response/{}/ccl_feature.csv'\n",
    "response_label_path = '../PM 1/data_InSummary/Drug_response/{}/response.csv'\n",
    "\n",
    "se_2_path = '../PM 1/data_InSummary/Drug_se/disease_embedding.csv'\n",
    "se_label_path = '../PM 1/data_InSummary/Drug_se/{}/data_afterSampling.csv'\n",
    "\n",
    "target_path = '../PM 1/data_InSummary/Drug_target/{}/data_sampled.parquet'\n",
    "\n",
    "\n",
    "ccle_1 = pd.read_csv(path.format(\"response\", \"ccle\"))\n",
    "ccle_2 = pd.read_csv(response_2_path.format(\"ccle\"))\n",
    "ccle_labels = pd.read_csv(response_label_path.format(\"ccle\"))\n",
    "gdsc_1 = pd.read_csv(path.format(\"response\", \"gdsc\"))\n",
    "gdsc_2 = pd.read_csv(response_2_path.format(\"gdsc\")).drop(['Unnamed: 0'], axis=1)\n",
    "gdsc_labels = pd.read_csv(response_label_path.format(\"gdsc\"))\n",
    "pdx_1 = pd.read_csv(path.format(\"response\", \"pdx\"))\n",
    "pdx_2 = pd.read_csv(response_2_path.format(\"pdx\")).drop(['Unnamed: 0'], axis=1)\n",
    "pdx_labels = pd.read_csv(response_label_path.format(\"pdx\"))\n",
    "\n",
    "offside = pd.read_csv(path.format(\"se\", \"offside\"))\n",
    "offside_labels = pd.read_csv(se_label_path.format(\"offside\"))\n",
    "sider = pd.read_csv(path.format(\"se\", \"sider\"))\n",
    "sider_labels = pd.read_csv(se_label_path.format(\"sider\"))\n",
    "se_2 = pd.read_csv(se_2_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d064e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "X_i, y_i = concatenate_label_data(ccle_1, ccle_2, ccle_labels)\n",
    "X.append(X_i)\n",
    "y.append(y_i)\n",
    "X_i, y_i = concatenate_label_data(gdsc_1, gdsc_2, gdsc_labels)\n",
    "X.append(X_i)\n",
    "y.append(y_i)\n",
    "X_i, y_i = concatenate_label_data(pdx_1, pdx_2, pdx_labels)\n",
    "X.append(X_i)\n",
    "y.append(y_i)\n",
    "X_i, y_i = concatenate_label_data(offside, se_2, offside_labels)\n",
    "X.append(X_i)\n",
    "y.append(y_i)\n",
    "X_i, y_i = concatenate_label_data(sider, se_2, sider_labels)\n",
    "X.append(X_i)\n",
    "y.append(y_i)\n",
    "print(len(X), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576d1f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "drugbank = pd.read_parquet(target_path.format(\"drugbank\"))\n",
    "repurposing_hub = pd.read_parquet(target_path.format(\"repurposing_hub\"))\n",
    "stitch = pd.read_parquet(target_path.format(\"stitch\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085c8c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_i = drugbank.iloc[:, 2:-1].values\n",
    "y_i = np.array(drugbank.iloc[:,-1:].values)\n",
    "X.append(X_i)\n",
    "y.append(y_i)\n",
    "X_i = repurposing_hub.iloc[:, 2:-1].values\n",
    "y_i = np.array(repurposing_hub.iloc[:,-1:].values)\n",
    "X.append(X_i)\n",
    "y.append(y_i)\n",
    "X_i = stitch.iloc[:, :-3].values\n",
    "y_i = np.array(stitch.iloc[:, -3:-2].values)\n",
    "X.append(X_i)\n",
    "y.append(y_i)\n",
    "\n",
    "print(len(X), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3a9a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "filenames = [\"drugbank\", \"repurposing_hub\", \"stitch\"]\n",
    "#filenames = [\"ccle\", \"gdsc\", \"pdx\", \"offside\", \"sider\"] \n",
    "\n",
    "for i in range(len(X)):\n",
    "    pca = PCA(n_components=50)\n",
    "    X_new = pca.fit_transform(X[i])\n",
    "    data = np.append(X_new, y[i], axis=1)\n",
    "    np.save(f'{filenames[i]}.npy', data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
